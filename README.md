[Pilnas darbas](https://github.com/PauliusMilmantas/Bakalaurinis_darbas/raw/master/Darbas/bakalaurinis.pdf)

[Pristatymas](https://github.com/PauliusMilmantas/Bakalaurinis_darbas/raw/master/Gynimas/Gynimas.pdf)

[Pristatymas konferencijai](https://github.com/PauliusMilmantas/Bakalaurinis_darbas/raw/master/Straipsnis/Pristatymas.pptx)

### Privačios informacijos išsaugojimas taikant dirbtinio intelekto technologijas

**Santrauka.** Straipsnyje   yra atliekamasapmokymui  skirtų  duomenų  saugumo  tyrimas  su skirtingais mašininio mokymosi modeliais.Modelių lyginimui apibrėžta metrika DMDK, kuri leidžia palyginti skirtingus modelius pagal jų pradinių mokymosi duomenų saugumo išsaugojimą. Maža DMDK reikšmė reiškia, kad tiriamas modelis yra linkęs atskleisti pradinius mokymosi duomenis ir nėra saugus.Atliktame tyrime pastebėta, kad PyTorch neuroniniai tinklai yra saugesni,  nei  homomorfiniu  šifravimu  grįstas  gradientinio  nuolydžio  modelis.Su   visais analizuotais modeliais, išskyrus PyTorch neuroninį tinklą, didėjant modelio tikslumui, didėja vidutinė DMDK reikšmė –modelis tampa saugesnis, o su PyTorch neuroniniu tinklu, mažėja -modelis tampa mažiau saugus.