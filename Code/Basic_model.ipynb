{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIzgXJHW-I2k"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from skimage import io\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "from google.colab import output"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CzjepVFB0B6"
      },
      "source": [
        "%mkdir results"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV6gHHYJ8KoT",
        "outputId": "ffba9e06-5c1e-4bbe-c768-56ab4371fa10"
      },
      "source": [
        "!git clone https://github.com/PauliusMilmantas/Bakalaurinis_darbas"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Bakalaurinis_darbas'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 106 (delta 38), reused 96 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (106/106), 1.58 MiB | 1.50 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MUJunKO8RWp",
        "outputId": "b8eb1614-8ba8-4227-b888-468edbbc9514"
      },
      "source": [
        "%cd /content/Bakalaurinis_darbas/Code"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Bakalaurinis_darbas/Code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gAQdhKZLiSR"
      },
      "source": [
        "def get_answer(output):\n",
        "  if output[0] > output[1]:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do-l7YQn-Qrt"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "class ORCDataset(Dataset):\n",
        "  def __init__(self, root):\n",
        "    self.root = root\n",
        "    self.data = pd.read_csv(root)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    dat = {}\n",
        "    dat['Pregnancies'] = self.data['Pregnancies'][idx]\n",
        "    dat['Glucose'] = self.data['Glucose'][idx]\n",
        "    dat['BloodPressure'] = self.data['BloodPressure'][idx]\n",
        "    dat['BMI'] = self.data['BMI'][idx]\n",
        "    dat['Age'] = self.data['Age'][idx]\n",
        "    found_type = self.data['Outcome'][idx]\n",
        "\n",
        "    return {'data': dat, 'class_name': found_type}\n",
        "\n",
        "train_dataset = ORCDataset('/content/Bakalaurinis_darbas/Code/train.csv')\n",
        "test_dataset = ORCDataset('/content/Bakalaurinis_darbas/Code/test.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEY-Wb1z98SD"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden1_size, hidden2_size, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden2_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)        \n",
        "        out = self.relu2(out)     \n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLcbrZyj_hXT"
      },
      "source": [
        "2 <- 7 <- 15 <- 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3GzBs6t_X0g",
        "outputId": "294b295c-d041-4ee5-8193-3958fd396c1d"
      },
      "source": [
        "network = Net(5, 15, 7, 2)\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=0.0001, momentum=0.6)\n",
        "criterion = nn.MSELoss().cuda()\n",
        "\n",
        "print(network)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=5, out_features=15, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=15, out_features=7, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (fc3): Linear(in_features=7, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MnOqoUK_vGx",
        "outputId": "233e3d8b-f6fa-40de-82ff-d8e23fa316d3"
      },
      "source": [
        "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "network.to(dev)\n",
        "criterion.to(dev)\n",
        "dev"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SQxeSmA_xaj",
        "outputId": "4ff2c3fb-7283-48af-8c19-d03cb0ffa74a"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "#Additional Info when using cuda\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLzLwFT0_0Mg"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = len(train_dataset),shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = len(test_dataset),shuffle=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1vxofpT_3YM",
        "outputId": "7c49a891-85fb-46da-fd94-e053a1ab368c"
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "itr = dataiter.next()\n",
        "\n",
        "label = itr['class_name']\n",
        "dat = itr['data']\n",
        "print(\"Class name: {} Data: [Pregnancies: {} Glucose: {} BloodPressure: {} BMI: {} Age: {}]\".format(label[0], dat['Pregnancies'][0], dat['Glucose'][0], dat['BloodPressure'][0], dat['BMI'][0], dat['Age'][0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class name: 1 Data: [Pregnancies: 8 Glucose: 124 BloodPressure: 76 BMI: 28.7 Age: 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "boQCZfH2Aukr",
        "outputId": "34dd54c4-cca1-410f-9bd0-4113b9e2be44"
      },
      "source": [
        "def train(train_loader, test_loader, epoch_amount, save_checkpoint = 10):\n",
        "  network.eval()\n",
        "  train_loss_hist = []\n",
        "  acc_history = []\n",
        "\n",
        "  checkpoint = save_checkpoint\n",
        "  for epoch in range(epoch_amount):\n",
        "    num_data_train = 0\n",
        "\n",
        "    # TRAINING DATASET\n",
        "    correct = 0\n",
        "    wrong = 0\n",
        "    for data in train_loader:\n",
        "      labels = torch.from_numpy(np.array(data['class_name']))\n",
        "      dat = data['data']\n",
        "\n",
        "      lossSum = 0\n",
        "\n",
        "      parsedData = []\n",
        "      for dictIdx in range(len(labels)):\n",
        "        parsedData.append(\n",
        "            np.array([dat['Pregnancies'][dictIdx].float(), dat['Glucose'][dictIdx].float(), dat['BloodPressure'][dictIdx].float(), dat['BMI'][dictIdx].float(), dat['Age'][dictIdx].float()])\n",
        "            )\n",
        "\n",
        "      for idx in range(len(labels)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = network(torch.Tensor(parsedData[idx].flatten()))\n",
        "        realAnswer = [0, 0]\n",
        "        realAnswer[labels[idx]] = 1\n",
        "\n",
        "        loss = criterion(outputs, torch.Tensor(realAnswer))\n",
        "          \n",
        "        loss.backward()\n",
        "\n",
        "        lossSum += loss.item()\n",
        "        train_loss_hist.append(lossSum)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    # TESTING DATASET\n",
        "    for data in test_loader:\n",
        "      labels = torch.from_numpy(np.array(data['class_name']))\n",
        "      dat = data['data']\n",
        "\n",
        "      parsedData = []\n",
        "      for dictIdx in range(len(labels)):\n",
        "        parsedData.append(\n",
        "            np.array([dat['Pregnancies'][dictIdx].float(), dat['Glucose'][dictIdx].float(), dat['BloodPressure'][dictIdx].float(), dat['BMI'][dictIdx].float(), dat['Age'][dictIdx].float()])\n",
        "            )\n",
        "\n",
        "      for idx in range(len(labels)):\n",
        "        outputs = network(torch.Tensor(parsedData[idx].flatten()))\n",
        "\n",
        "        predicted = get_answer(outputs)\n",
        "        real_answer = labels[idx].item()\n",
        "\n",
        "        if predicted == real_answer:\n",
        "          correct += 1\n",
        "        else:\n",
        "          wrong += 1\n",
        "\n",
        "    acc_history.append(\n",
        "        correct/(correct+wrong)*100\n",
        "    )\n",
        "    print(\"Epoch: {} Training loss: {} Accuracy: {}\".format(epoch,train_loss_hist[len(train_loss_hist) - 1], acc_history[len(acc_history) - 1]))\n",
        "    \n",
        "    if(checkpoint == 0):\n",
        "      torch.save(network.state_dict(), '/content/results/model.pth')\n",
        "      torch.save(optimizer.state_dict(), '/content/results/optimizer.pth')\n",
        "\n",
        "      checkpoint = save_checkpoint\n",
        "    else:\n",
        "      checkpoint -= 1\n",
        "\n",
        "  plt.plot(np.arange(0, len(train_loss_hist), 1), train_loss_hist)\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(np.arange(0, len(acc_history), 1), acc_history)\n",
        "  plt.show()\n",
        "\n",
        "train(train_loader, test_loader, 500)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Training loss: 290.08104797033593 Accuracy: 63.905325443786985\n",
            "Epoch: 1 Training loss: 176.12656165621593 Accuracy: 52.071005917159766\n",
            "Epoch: 2 Training loss: 167.5912026331207 Accuracy: 65.08875739644971\n",
            "Epoch: 3 Training loss: 156.7179423889611 Accuracy: 65.08875739644971\n",
            "Epoch: 4 Training loss: 151.26829836628167 Accuracy: 36.09467455621302\n",
            "Epoch: 5 Training loss: 150.56647447124124 Accuracy: 64.49704142011834\n",
            "Epoch: 6 Training loss: 149.46199752646498 Accuracy: 64.49704142011834\n",
            "Epoch: 7 Training loss: 148.5932958740741 Accuracy: 65.68047337278107\n",
            "Epoch: 8 Training loss: 147.00624573230743 Accuracy: 64.49704142011834\n",
            "Epoch: 9 Training loss: 145.58912044484168 Accuracy: 66.27218934911244\n",
            "Epoch: 10 Training loss: 145.00148846385127 Accuracy: 64.49704142011834\n",
            "Epoch: 11 Training loss: 143.88020140025765 Accuracy: 66.27218934911244\n",
            "Epoch: 12 Training loss: 142.3107565883547 Accuracy: 66.27218934911244\n",
            "Epoch: 13 Training loss: 142.0586688600015 Accuracy: 65.68047337278107\n",
            "Epoch: 14 Training loss: 140.9171396442689 Accuracy: 66.27218934911244\n",
            "Epoch: 15 Training loss: 139.6857873853296 Accuracy: 64.49704142011834\n",
            "Epoch: 16 Training loss: 140.37470701581333 Accuracy: 66.86390532544378\n",
            "Epoch: 17 Training loss: 138.78541599144228 Accuracy: 66.27218934911244\n",
            "Epoch: 18 Training loss: 138.97519426699728 Accuracy: 65.68047337278107\n",
            "Epoch: 19 Training loss: 138.96115105506033 Accuracy: 65.08875739644971\n",
            "Epoch: 20 Training loss: 137.16821023495868 Accuracy: 65.68047337278107\n",
            "Epoch: 21 Training loss: 136.7827059244737 Accuracy: 66.86390532544378\n",
            "Epoch: 22 Training loss: 137.29185089282691 Accuracy: 66.86390532544378\n",
            "Epoch: 23 Training loss: 135.8480956996791 Accuracy: 66.86390532544378\n",
            "Epoch: 24 Training loss: 136.03933278284967 Accuracy: 66.27218934911244\n",
            "Epoch: 25 Training loss: 134.16624542797217 Accuracy: 66.86390532544378\n",
            "Epoch: 26 Training loss: 134.10103709287068 Accuracy: 67.45562130177515\n",
            "Epoch: 27 Training loss: 133.8990663262084 Accuracy: 67.45562130177515\n",
            "Epoch: 28 Training loss: 133.25576437109703 Accuracy: 68.04733727810651\n",
            "Epoch: 29 Training loss: 131.9514589979517 Accuracy: 64.49704142011834\n",
            "Epoch: 30 Training loss: 132.939913266222 Accuracy: 67.45562130177515\n",
            "Epoch: 31 Training loss: 130.01072526706776 Accuracy: 57.396449704142015\n",
            "Epoch: 32 Training loss: 132.3958262205124 Accuracy: 66.86390532544378\n",
            "Epoch: 33 Training loss: 129.95941391593078 Accuracy: 68.63905325443787\n",
            "Epoch: 34 Training loss: 129.70322157314877 Accuracy: 68.04733727810651\n",
            "Epoch: 35 Training loss: 129.90584579376446 Accuracy: 66.27218934911244\n",
            "Epoch: 36 Training loss: 130.38900836266112 Accuracy: 66.86390532544378\n",
            "Epoch: 37 Training loss: 130.84498360054567 Accuracy: 68.63905325443787\n",
            "Epoch: 38 Training loss: 128.50943822681438 Accuracy: 60.35502958579882\n",
            "Epoch: 39 Training loss: 129.8669588281773 Accuracy: 66.86390532544378\n",
            "Epoch: 40 Training loss: 128.76231396419462 Accuracy: 71.59763313609467\n",
            "Epoch: 41 Training loss: 127.0489801220865 Accuracy: 71.59763313609467\n",
            "Epoch: 42 Training loss: 129.15293379226932 Accuracy: 69.23076923076923\n",
            "Epoch: 43 Training loss: 128.04712024275796 Accuracy: 68.63905325443787\n",
            "Epoch: 44 Training loss: 127.80348204186885 Accuracy: 66.86390532544378\n",
            "Epoch: 45 Training loss: 127.2519506503595 Accuracy: 68.04733727810651\n",
            "Epoch: 46 Training loss: 126.25133056464256 Accuracy: 70.41420118343196\n",
            "Epoch: 47 Training loss: 127.34453045134433 Accuracy: 70.41420118343196\n",
            "Epoch: 48 Training loss: 127.1179411689518 Accuracy: 70.41420118343196\n",
            "Epoch: 49 Training loss: 126.31149804079905 Accuracy: 72.7810650887574\n",
            "Epoch: 50 Training loss: 125.88499397435226 Accuracy: 71.00591715976331\n",
            "Epoch: 51 Training loss: 126.33654044591822 Accuracy: 70.41420118343196\n",
            "Epoch: 52 Training loss: 124.53216493874788 Accuracy: 71.59763313609467\n",
            "Epoch: 53 Training loss: 125.06382192325691 Accuracy: 69.8224852071006\n",
            "Epoch: 54 Training loss: 124.38159407576313 Accuracy: 70.41420118343196\n",
            "Epoch: 55 Training loss: 123.9530409516301 Accuracy: 70.41420118343196\n",
            "Epoch: 56 Training loss: 124.52123669727007 Accuracy: 73.37278106508876\n",
            "Epoch: 57 Training loss: 124.29020603385288 Accuracy: 71.00591715976331\n",
            "Epoch: 58 Training loss: 122.77225995971821 Accuracy: 68.04733727810651\n",
            "Epoch: 59 Training loss: 122.83148150000488 Accuracy: 73.96449704142012\n",
            "Epoch: 60 Training loss: 124.55150830477942 Accuracy: 72.7810650887574\n",
            "Epoch: 61 Training loss: 123.14771880814806 Accuracy: 73.96449704142012\n",
            "Epoch: 62 Training loss: 120.85770809196401 Accuracy: 73.96449704142012\n",
            "Epoch: 63 Training loss: 122.0905425252131 Accuracy: 73.37278106508876\n",
            "Epoch: 64 Training loss: 120.9140579278901 Accuracy: 70.41420118343196\n",
            "Epoch: 65 Training loss: 122.7792746941559 Accuracy: 70.41420118343196\n",
            "Epoch: 66 Training loss: 122.1699183464516 Accuracy: 70.41420118343196\n",
            "Epoch: 67 Training loss: 122.4962829775177 Accuracy: 70.41420118343196\n",
            "Epoch: 68 Training loss: 121.06993864977267 Accuracy: 68.63905325443787\n",
            "Epoch: 69 Training loss: 121.24146905669477 Accuracy: 71.59763313609467\n",
            "Epoch: 70 Training loss: 120.61672567261849 Accuracy: 69.23076923076923\n",
            "Epoch: 71 Training loss: 120.53868108056486 Accuracy: 74.55621301775149\n",
            "Epoch: 72 Training loss: 119.99070441490039 Accuracy: 72.18934911242604\n",
            "Epoch: 73 Training loss: 120.91616490809247 Accuracy: 73.37278106508876\n",
            "Epoch: 74 Training loss: 120.54835670266766 Accuracy: 71.59763313609467\n",
            "Epoch: 75 Training loss: 119.52655978128314 Accuracy: 71.59763313609467\n",
            "Epoch: 76 Training loss: 118.11547870835784 Accuracy: 74.55621301775149\n",
            "Epoch: 77 Training loss: 120.65886640327517 Accuracy: 73.37278106508876\n",
            "Epoch: 78 Training loss: 120.00150023843162 Accuracy: 68.63905325443787\n",
            "Epoch: 79 Training loss: 119.2582627136726 Accuracy: 71.59763313609467\n",
            "Epoch: 80 Training loss: 117.87870712421864 Accuracy: 74.55621301775149\n",
            "Epoch: 81 Training loss: 119.19990747235715 Accuracy: 74.55621301775149\n",
            "Epoch: 82 Training loss: 118.19761431442748 Accuracy: 75.14792899408283\n",
            "Epoch: 83 Training loss: 119.48897595937888 Accuracy: 71.59763313609467\n",
            "Epoch: 84 Training loss: 119.35676455229986 Accuracy: 75.7396449704142\n",
            "Epoch: 85 Training loss: 117.74406218868171 Accuracy: 75.14792899408283\n",
            "Epoch: 86 Training loss: 118.17491761251586 Accuracy: 75.14792899408283\n",
            "Epoch: 87 Training loss: 118.44798362744041 Accuracy: 73.37278106508876\n",
            "Epoch: 88 Training loss: 117.33378809739406 Accuracy: 73.96449704142012\n",
            "Epoch: 89 Training loss: 117.15211845999875 Accuracy: 73.37278106508876\n",
            "Epoch: 90 Training loss: 117.80051660703612 Accuracy: 72.7810650887574\n",
            "Epoch: 91 Training loss: 117.27487219218165 Accuracy: 76.33136094674556\n",
            "Epoch: 92 Training loss: 117.64824391977163 Accuracy: 72.18934911242604\n",
            "Epoch: 93 Training loss: 116.2994948105079 Accuracy: 71.59763313609467\n",
            "Epoch: 94 Training loss: 116.54671462751139 Accuracy: 71.59763313609467\n",
            "Epoch: 95 Training loss: 116.76207794935908 Accuracy: 72.18934911242604\n",
            "Epoch: 96 Training loss: 116.67915274591724 Accuracy: 72.7810650887574\n",
            "Epoch: 97 Training loss: 116.13388893657248 Accuracy: 72.18934911242604\n",
            "Epoch: 98 Training loss: 116.18347926676506 Accuracy: 72.18934911242604\n",
            "Epoch: 99 Training loss: 116.32047736935783 Accuracy: 76.33136094674556\n",
            "Epoch: 100 Training loss: 112.5099294306383 Accuracy: 72.7810650887574\n",
            "Epoch: 101 Training loss: 115.68851703162363 Accuracy: 77.51479289940828\n",
            "Epoch: 102 Training loss: 115.72209407397531 Accuracy: 74.55621301775149\n",
            "Epoch: 103 Training loss: 114.42342006191029 Accuracy: 71.59763313609467\n",
            "Epoch: 104 Training loss: 115.0203223526878 Accuracy: 76.33136094674556\n",
            "Epoch: 105 Training loss: 114.97682591526791 Accuracy: 71.00591715976331\n",
            "Epoch: 106 Training loss: 114.54967705204035 Accuracy: 71.00591715976331\n",
            "Epoch: 107 Training loss: 114.79465752129909 Accuracy: 72.7810650887574\n",
            "Epoch: 108 Training loss: 115.11783351251506 Accuracy: 76.92307692307693\n",
            "Epoch: 109 Training loss: 114.77658560342388 Accuracy: 78.10650887573965\n",
            "Epoch: 110 Training loss: 113.51054717631257 Accuracy: 71.59763313609467\n",
            "Epoch: 111 Training loss: 114.09228603310476 Accuracy: 76.92307692307693\n",
            "Epoch: 112 Training loss: 114.9788903069566 Accuracy: 76.92307692307693\n",
            "Epoch: 113 Training loss: 114.04787516430952 Accuracy: 78.10650887573965\n",
            "Epoch: 114 Training loss: 115.1286580201704 Accuracy: 79.28994082840237\n",
            "Epoch: 115 Training loss: 113.97746361728059 Accuracy: 76.92307692307693\n",
            "Epoch: 116 Training loss: 114.02363939750649 Accuracy: 71.59763313609467\n",
            "Epoch: 117 Training loss: 114.70211607549572 Accuracy: 71.00591715976331\n",
            "Epoch: 118 Training loss: 113.44175669772085 Accuracy: 71.59763313609467\n",
            "Epoch: 119 Training loss: 111.88599121206789 Accuracy: 76.33136094674556\n",
            "Epoch: 120 Training loss: 113.5163908025861 Accuracy: 73.96449704142012\n",
            "Epoch: 121 Training loss: 114.62050310111226 Accuracy: 80.4733727810651\n",
            "Epoch: 122 Training loss: 113.63237125554588 Accuracy: 73.96449704142012\n",
            "Epoch: 123 Training loss: 113.69173224503174 Accuracy: 70.41420118343196\n",
            "Epoch: 124 Training loss: 113.53568206937052 Accuracy: 75.14792899408283\n",
            "Epoch: 125 Training loss: 112.43625306300237 Accuracy: 73.37278106508876\n",
            "Epoch: 126 Training loss: 112.78492758049106 Accuracy: 71.00591715976331\n",
            "Epoch: 127 Training loss: 111.09242224891204 Accuracy: 75.7396449704142\n",
            "Epoch: 128 Training loss: 111.41678930533817 Accuracy: 78.69822485207101\n",
            "Epoch: 129 Training loss: 111.60060696063738 Accuracy: 68.63905325443787\n",
            "Epoch: 130 Training loss: 111.58612139342586 Accuracy: 79.28994082840237\n",
            "Epoch: 131 Training loss: 111.61335971445078 Accuracy: 79.28994082840237\n",
            "Epoch: 132 Training loss: 112.51591072999872 Accuracy: 79.88165680473372\n",
            "Epoch: 133 Training loss: 112.32125855388585 Accuracy: 72.18934911242604\n",
            "Epoch: 134 Training loss: 111.89242860184459 Accuracy: 77.51479289940828\n",
            "Epoch: 135 Training loss: 111.12843027713825 Accuracy: 71.59763313609467\n",
            "Epoch: 136 Training loss: 111.79002882758505 Accuracy: 74.55621301775149\n",
            "Epoch: 137 Training loss: 111.23396552156191 Accuracy: 71.59763313609467\n",
            "Epoch: 138 Training loss: 111.31978815114417 Accuracy: 69.23076923076923\n",
            "Epoch: 139 Training loss: 112.20421991776675 Accuracy: 79.88165680473372\n",
            "Epoch: 140 Training loss: 110.24558551678638 Accuracy: 71.00591715976331\n",
            "Epoch: 141 Training loss: 109.52983825847332 Accuracy: 78.69822485207101\n",
            "Epoch: 142 Training loss: 111.62292607596464 Accuracy: 74.55621301775149\n",
            "Epoch: 143 Training loss: 111.11896519525908 Accuracy: 76.92307692307693\n",
            "Epoch: 144 Training loss: 110.75409543601563 Accuracy: 78.10650887573965\n",
            "Epoch: 145 Training loss: 110.88831385562662 Accuracy: 77.51479289940828\n",
            "Epoch: 146 Training loss: 109.52410278766001 Accuracy: 71.59763313609467\n",
            "Epoch: 147 Training loss: 111.7139943872462 Accuracy: 75.7396449704142\n",
            "Epoch: 148 Training loss: 110.8222601411544 Accuracy: 79.88165680473372\n",
            "Epoch: 149 Training loss: 110.42687323830614 Accuracy: 81.65680473372781\n",
            "Epoch: 150 Training loss: 109.6131681046354 Accuracy: 70.41420118343196\n",
            "Epoch: 151 Training loss: 110.20905239003423 Accuracy: 81.06508875739645\n",
            "Epoch: 152 Training loss: 110.31968780426541 Accuracy: 76.33136094674556\n",
            "Epoch: 153 Training loss: 110.04011129256105 Accuracy: 77.51479289940828\n",
            "Epoch: 154 Training loss: 109.35623028193004 Accuracy: 82.24852071005917\n",
            "Epoch: 155 Training loss: 109.07971665844525 Accuracy: 72.7810650887574\n",
            "Epoch: 156 Training loss: 109.63541608866217 Accuracy: 75.14792899408283\n",
            "Epoch: 157 Training loss: 109.51167823475407 Accuracy: 79.28994082840237\n",
            "Epoch: 158 Training loss: 108.17733626093832 Accuracy: 75.14792899408283\n",
            "Epoch: 159 Training loss: 108.86398883468064 Accuracy: 72.7810650887574\n",
            "Epoch: 160 Training loss: 109.79328422248363 Accuracy: 75.7396449704142\n",
            "Epoch: 161 Training loss: 109.40015321445753 Accuracy: 79.88165680473372\n",
            "Epoch: 162 Training loss: 109.16000094359333 Accuracy: 75.14792899408283\n",
            "Epoch: 163 Training loss: 107.31206685014695 Accuracy: 70.41420118343196\n",
            "Epoch: 164 Training loss: 108.31352099936339 Accuracy: 80.4733727810651\n",
            "Epoch: 165 Training loss: 109.2270341150579 Accuracy: 72.7810650887574\n",
            "Epoch: 166 Training loss: 108.86776507797185 Accuracy: 74.55621301775149\n",
            "Epoch: 167 Training loss: 108.7408314330678 Accuracy: 73.96449704142012\n",
            "Epoch: 168 Training loss: 108.24727869595517 Accuracy: 74.55621301775149\n",
            "Epoch: 169 Training loss: 108.12385106773581 Accuracy: 71.00591715976331\n",
            "Epoch: 170 Training loss: 108.87428739317147 Accuracy: 81.65680473372781\n",
            "Epoch: 171 Training loss: 107.38821312761866 Accuracy: 71.59763313609467\n",
            "Epoch: 172 Training loss: 106.09192368900403 Accuracy: 75.7396449704142\n",
            "Epoch: 173 Training loss: 107.1317194217554 Accuracy: 81.06508875739645\n",
            "Epoch: 174 Training loss: 107.61402245333011 Accuracy: 73.37278106508876\n",
            "Epoch: 175 Training loss: 107.49359892585198 Accuracy: 81.06508875739645\n",
            "Epoch: 176 Training loss: 107.94678997789742 Accuracy: 75.7396449704142\n",
            "Epoch: 177 Training loss: 106.91734892989916 Accuracy: 75.7396449704142\n",
            "Epoch: 178 Training loss: 108.30527911487661 Accuracy: 75.7396449704142\n",
            "Epoch: 179 Training loss: 107.73818877532904 Accuracy: 74.55621301775149\n",
            "Epoch: 180 Training loss: 105.2521855533123 Accuracy: 81.65680473372781\n",
            "Epoch: 181 Training loss: 106.32554990318022 Accuracy: 70.41420118343196\n",
            "Epoch: 182 Training loss: 105.8930340266379 Accuracy: 75.7396449704142\n",
            "Epoch: 183 Training loss: 107.93159044877393 Accuracy: 70.41420118343196\n",
            "Epoch: 184 Training loss: 105.86570303578992 Accuracy: 76.33136094674556\n",
            "Epoch: 185 Training loss: 107.05318747859565 Accuracy: 75.14792899408283\n",
            "Epoch: 186 Training loss: 106.56398459200864 Accuracy: 70.41420118343196\n",
            "Epoch: 187 Training loss: 107.25080623073154 Accuracy: 80.4733727810651\n",
            "Epoch: 188 Training loss: 106.9928942220431 Accuracy: 81.06508875739645\n",
            "Epoch: 189 Training loss: 106.96584852873639 Accuracy: 76.92307692307693\n",
            "Epoch: 190 Training loss: 106.7114683914615 Accuracy: 73.96449704142012\n",
            "Epoch: 191 Training loss: 105.18052340234863 Accuracy: 81.06508875739645\n",
            "Epoch: 192 Training loss: 107.57819233165355 Accuracy: 79.28994082840237\n",
            "Epoch: 193 Training loss: 106.61014502243415 Accuracy: 70.41420118343196\n",
            "Epoch: 194 Training loss: 106.45015549496748 Accuracy: 74.55621301775149\n",
            "Epoch: 195 Training loss: 105.85090459091589 Accuracy: 71.00591715976331\n",
            "Epoch: 196 Training loss: 105.72180540430418 Accuracy: 79.88165680473372\n",
            "Epoch: 197 Training loss: 105.34904486539017 Accuracy: 70.41420118343196\n",
            "Epoch: 198 Training loss: 106.58430914449855 Accuracy: 78.10650887573965\n",
            "Epoch: 199 Training loss: 105.96779374225298 Accuracy: 69.8224852071006\n",
            "Epoch: 200 Training loss: 105.31794675649144 Accuracy: 69.8224852071006\n",
            "Epoch: 201 Training loss: 106.78466877117171 Accuracy: 71.00591715976331\n",
            "Epoch: 202 Training loss: 106.305480699084 Accuracy: 77.51479289940828\n",
            "Epoch: 203 Training loss: 106.04388463446503 Accuracy: 69.8224852071006\n",
            "Epoch: 204 Training loss: 104.11189911614929 Accuracy: 72.18934911242604\n",
            "Epoch: 205 Training loss: 104.83317264876678 Accuracy: 77.51479289940828\n",
            "Epoch: 206 Training loss: 105.87753086097655 Accuracy: 75.14792899408283\n",
            "Epoch: 207 Training loss: 105.62224610699923 Accuracy: 78.69822485207101\n",
            "Epoch: 208 Training loss: 105.37758645883514 Accuracy: 80.4733727810651\n",
            "Epoch: 209 Training loss: 106.20824203962547 Accuracy: 80.4733727810651\n",
            "Epoch: 210 Training loss: 105.70775923023757 Accuracy: 72.7810650887574\n",
            "Epoch: 211 Training loss: 105.7686259059983 Accuracy: 73.96449704142012\n",
            "Epoch: 212 Training loss: 105.69759437006724 Accuracy: 74.55621301775149\n",
            "Epoch: 213 Training loss: 104.69589324999833 Accuracy: 72.7810650887574\n",
            "Epoch: 214 Training loss: 105.17533175030258 Accuracy: 71.00591715976331\n",
            "Epoch: 215 Training loss: 103.78591448505176 Accuracy: 73.37278106508876\n",
            "Epoch: 216 Training loss: 104.40039820647507 Accuracy: 74.55621301775149\n",
            "Epoch: 217 Training loss: 104.00959123219945 Accuracy: 79.28994082840237\n",
            "Epoch: 218 Training loss: 105.20502311724704 Accuracy: 79.28994082840237\n",
            "Epoch: 219 Training loss: 102.98236787421229 Accuracy: 69.23076923076923\n",
            "Epoch: 220 Training loss: 103.21627797461406 Accuracy: 80.4733727810651\n",
            "Epoch: 221 Training loss: 104.5939697113754 Accuracy: 80.4733727810651\n",
            "Epoch: 222 Training loss: 104.46323030057829 Accuracy: 76.92307692307693\n",
            "Epoch: 223 Training loss: 102.34304569811502 Accuracy: 77.51479289940828\n",
            "Epoch: 224 Training loss: 104.31951257510809 Accuracy: 79.88165680473372\n",
            "Epoch: 225 Training loss: 103.52270478023274 Accuracy: 72.18934911242604\n",
            "Epoch: 226 Training loss: 105.1946845984894 Accuracy: 72.7810650887574\n",
            "Epoch: 227 Training loss: 102.8771109591471 Accuracy: 79.28994082840237\n",
            "Epoch: 228 Training loss: 104.46179389342433 Accuracy: 79.28994082840237\n",
            "Epoch: 229 Training loss: 103.39699343821121 Accuracy: 76.33136094674556\n",
            "Epoch: 230 Training loss: 104.12223431267194 Accuracy: 73.96449704142012\n",
            "Epoch: 231 Training loss: 103.64971395513567 Accuracy: 71.59763313609467\n",
            "Epoch: 232 Training loss: 103.91089427699808 Accuracy: 79.88165680473372\n",
            "Epoch: 233 Training loss: 103.36932418372817 Accuracy: 78.10650887573965\n",
            "Epoch: 234 Training loss: 104.52398462238489 Accuracy: 74.55621301775149\n",
            "Epoch: 235 Training loss: 104.04672648207634 Accuracy: 79.28994082840237\n",
            "Epoch: 236 Training loss: 102.48718316812301 Accuracy: 80.4733727810651\n",
            "Epoch: 237 Training loss: 104.05096966843121 Accuracy: 79.88165680473372\n",
            "Epoch: 238 Training loss: 103.77978477352008 Accuracy: 78.69822485207101\n",
            "Epoch: 239 Training loss: 103.43283297626567 Accuracy: 74.55621301775149\n",
            "Epoch: 240 Training loss: 102.97069025979727 Accuracy: 74.55621301775149\n",
            "Epoch: 241 Training loss: 103.42200151056204 Accuracy: 81.06508875739645\n",
            "Epoch: 242 Training loss: 103.73417611847981 Accuracy: 78.10650887573965\n",
            "Epoch: 243 Training loss: 103.14973243675001 Accuracy: 68.63905325443787\n",
            "Epoch: 244 Training loss: 102.84738690157246 Accuracy: 82.24852071005917\n",
            "Epoch: 245 Training loss: 103.09151998078596 Accuracy: 81.06508875739645\n",
            "Epoch: 246 Training loss: 101.73497057904024 Accuracy: 72.18934911242604\n",
            "Epoch: 247 Training loss: 102.51189439327572 Accuracy: 81.06508875739645\n",
            "Epoch: 248 Training loss: 102.74312719771842 Accuracy: 80.4733727810651\n",
            "Epoch: 249 Training loss: 102.7177650923868 Accuracy: 79.28994082840237\n",
            "Epoch: 250 Training loss: 101.85442964060348 Accuracy: 79.28994082840237\n",
            "Epoch: 251 Training loss: 102.62479274967336 Accuracy: 78.10650887573965\n",
            "Epoch: 252 Training loss: 102.96000443683442 Accuracy: 71.59763313609467\n",
            "Epoch: 253 Training loss: 103.1168924509584 Accuracy: 75.7396449704142\n",
            "Epoch: 254 Training loss: 100.69679602473843 Accuracy: 79.28994082840237\n",
            "Epoch: 255 Training loss: 102.86801899939019 Accuracy: 79.88165680473372\n",
            "Epoch: 256 Training loss: 102.1372276370821 Accuracy: 72.7810650887574\n",
            "Epoch: 257 Training loss: 101.93178450257983 Accuracy: 79.28994082840237\n",
            "Epoch: 258 Training loss: 101.71333059863537 Accuracy: 78.69822485207101\n",
            "Epoch: 259 Training loss: 102.85211526326475 Accuracy: 75.14792899408283\n",
            "Epoch: 260 Training loss: 102.41704271585331 Accuracy: 78.10650887573965\n",
            "Epoch: 261 Training loss: 101.31892116171639 Accuracy: 79.28994082840237\n",
            "Epoch: 262 Training loss: 102.69916017343712 Accuracy: 79.28994082840237\n",
            "Epoch: 263 Training loss: 101.83450126143362 Accuracy: 77.51479289940828\n",
            "Epoch: 264 Training loss: 101.94893762616266 Accuracy: 79.28994082840237\n",
            "Epoch: 265 Training loss: 101.2638411565058 Accuracy: 69.23076923076923\n",
            "Epoch: 266 Training loss: 101.26870387165036 Accuracy: 80.4733727810651\n",
            "Epoch: 267 Training loss: 101.48302616568981 Accuracy: 79.88165680473372\n",
            "Epoch: 268 Training loss: 101.22349940038839 Accuracy: 72.7810650887574\n",
            "Epoch: 269 Training loss: 101.01885036506428 Accuracy: 72.7810650887574\n",
            "Epoch: 270 Training loss: 101.2083064030885 Accuracy: 81.06508875739645\n",
            "Epoch: 271 Training loss: 101.65191857257742 Accuracy: 69.23076923076923\n",
            "Epoch: 272 Training loss: 101.16146334499263 Accuracy: 76.92307692307693\n",
            "Epoch: 273 Training loss: 101.01711514143972 Accuracy: 81.65680473372781\n",
            "Epoch: 274 Training loss: 100.90623467355181 Accuracy: 78.69822485207101\n",
            "Epoch: 275 Training loss: 100.69671806457336 Accuracy: 77.51479289940828\n",
            "Epoch: 276 Training loss: 101.85765390654342 Accuracy: 79.28994082840237\n",
            "Epoch: 277 Training loss: 100.58408319564478 Accuracy: 81.65680473372781\n",
            "Epoch: 278 Training loss: 101.3003357734924 Accuracy: 72.18934911242604\n",
            "Epoch: 279 Training loss: 101.20508167265507 Accuracy: 76.92307692307693\n",
            "Epoch: 280 Training loss: 101.59462836594685 Accuracy: 79.88165680473372\n",
            "Epoch: 281 Training loss: 101.09063256840454 Accuracy: 78.10650887573965\n",
            "Epoch: 282 Training loss: 100.71774967341298 Accuracy: 75.14792899408283\n",
            "Epoch: 283 Training loss: 101.41832345094008 Accuracy: 75.7396449704142\n",
            "Epoch: 284 Training loss: 100.95493614050793 Accuracy: 72.7810650887574\n",
            "Epoch: 285 Training loss: 99.92468704298881 Accuracy: 68.63905325443787\n",
            "Epoch: 286 Training loss: 100.2534093031718 Accuracy: 79.28994082840237\n",
            "Epoch: 287 Training loss: 100.63446274970192 Accuracy: 81.06508875739645\n",
            "Epoch: 288 Training loss: 101.0373824668568 Accuracy: 79.88165680473372\n",
            "Epoch: 289 Training loss: 100.68626729867901 Accuracy: 72.18934911242604\n",
            "Epoch: 290 Training loss: 101.18169574884814 Accuracy: 78.10650887573965\n",
            "Epoch: 291 Training loss: 100.01079827751892 Accuracy: 72.7810650887574\n",
            "Epoch: 292 Training loss: 100.71485851841135 Accuracy: 71.59763313609467\n",
            "Epoch: 293 Training loss: 99.86728363428847 Accuracy: 76.33136094674556\n",
            "Epoch: 294 Training loss: 100.82662542403705 Accuracy: 80.4733727810651\n",
            "Epoch: 295 Training loss: 100.38828165850282 Accuracy: 81.65680473372781\n",
            "Epoch: 296 Training loss: 99.79885429778733 Accuracy: 79.88165680473372\n",
            "Epoch: 297 Training loss: 100.29129777626804 Accuracy: 78.10650887573965\n",
            "Epoch: 298 Training loss: 99.75776241510175 Accuracy: 81.06508875739645\n",
            "Epoch: 299 Training loss: 100.09721586105297 Accuracy: 76.33136094674556\n",
            "Epoch: 300 Training loss: 99.76264004625409 Accuracy: 72.7810650887574\n",
            "Epoch: 301 Training loss: 100.5302384852057 Accuracy: 79.88165680473372\n",
            "Epoch: 302 Training loss: 95.88919315200474 Accuracy: 69.23076923076923\n",
            "Epoch: 303 Training loss: 100.13407510916295 Accuracy: 73.96449704142012\n",
            "Epoch: 304 Training loss: 100.44212766679993 Accuracy: 73.37278106508876\n",
            "Epoch: 305 Training loss: 100.21849641783047 Accuracy: 72.7810650887574\n",
            "Epoch: 306 Training loss: 98.85189072876165 Accuracy: 79.28994082840237\n",
            "Epoch: 307 Training loss: 99.72584239194839 Accuracy: 79.28994082840237\n",
            "Epoch: 308 Training loss: 100.19661921808802 Accuracy: 81.65680473372781\n",
            "Epoch: 309 Training loss: 99.70038139310782 Accuracy: 78.69822485207101\n",
            "Epoch: 310 Training loss: 97.99121414417459 Accuracy: 70.41420118343196\n",
            "Epoch: 311 Training loss: 100.31516308957362 Accuracy: 79.28994082840237\n",
            "Epoch: 312 Training loss: 99.56048490462854 Accuracy: 79.88165680473372\n",
            "Epoch: 313 Training loss: 99.3158702357905 Accuracy: 78.69822485207101\n",
            "Epoch: 314 Training loss: 99.15517535168405 Accuracy: 81.06508875739645\n",
            "Epoch: 315 Training loss: 97.90661935077787 Accuracy: 81.65680473372781\n",
            "Epoch: 316 Training loss: 98.29529078435007 Accuracy: 73.37278106508876\n",
            "Epoch: 317 Training loss: 97.30419502372979 Accuracy: 79.28994082840237\n",
            "Epoch: 318 Training loss: 99.82415885764931 Accuracy: 81.06508875739645\n",
            "Epoch: 319 Training loss: 98.67647840954669 Accuracy: 79.28994082840237\n",
            "Epoch: 320 Training loss: 99.4083975595604 Accuracy: 79.28994082840237\n",
            "Epoch: 321 Training loss: 99.29986129393365 Accuracy: 72.7810650887574\n",
            "Epoch: 322 Training loss: 99.05946752714135 Accuracy: 78.69822485207101\n",
            "Epoch: 323 Training loss: 99.2431210763425 Accuracy: 76.33136094674556\n",
            "Epoch: 324 Training loss: 98.94769041629479 Accuracy: 78.69822485207101\n",
            "Epoch: 325 Training loss: 99.71809741638572 Accuracy: 81.06508875739645\n",
            "Epoch: 326 Training loss: 99.29968933910641 Accuracy: 80.4733727810651\n",
            "Epoch: 327 Training loss: 97.89410357816087 Accuracy: 76.92307692307693\n",
            "Epoch: 328 Training loss: 97.9308017186413 Accuracy: 79.88165680473372\n",
            "Epoch: 329 Training loss: 99.43625937087745 Accuracy: 71.00591715976331\n",
            "Epoch: 330 Training loss: 98.77132790172982 Accuracy: 79.28994082840237\n",
            "Epoch: 331 Training loss: 98.48232472467862 Accuracy: 69.8224852071006\n",
            "Epoch: 332 Training loss: 97.54856233232022 Accuracy: 76.92307692307693\n",
            "Epoch: 333 Training loss: 98.40080872759427 Accuracy: 82.24852071005917\n",
            "Epoch: 334 Training loss: 98.60136373763453 Accuracy: 79.88165680473372\n",
            "Epoch: 335 Training loss: 98.37184024490853 Accuracy: 72.7810650887574\n",
            "Epoch: 336 Training loss: 98.41001450947078 Accuracy: 73.96449704142012\n",
            "Epoch: 337 Training loss: 97.56796487406064 Accuracy: 81.65680473372781\n",
            "Epoch: 338 Training loss: 99.6641035737448 Accuracy: 78.69822485207101\n",
            "Epoch: 339 Training loss: 99.05093196661619 Accuracy: 78.10650887573965\n",
            "Epoch: 340 Training loss: 98.17804156681814 Accuracy: 78.69822485207101\n",
            "Epoch: 341 Training loss: 98.89250778228597 Accuracy: 80.4733727810651\n",
            "Epoch: 342 Training loss: 98.75852577538899 Accuracy: 79.88165680473372\n",
            "Epoch: 343 Training loss: 97.5218149007269 Accuracy: 73.37278106508876\n",
            "Epoch: 344 Training loss: 98.3908428762586 Accuracy: 75.7396449704142\n",
            "Epoch: 345 Training loss: 96.81743520118289 Accuracy: 78.10650887573965\n",
            "Epoch: 346 Training loss: 99.45492946234629 Accuracy: 78.69822485207101\n",
            "Epoch: 347 Training loss: 98.54456655810282 Accuracy: 78.69822485207101\n",
            "Epoch: 348 Training loss: 98.44141390551886 Accuracy: 81.65680473372781\n",
            "Epoch: 349 Training loss: 97.59178475759472 Accuracy: 79.28994082840237\n",
            "Epoch: 350 Training loss: 98.69232115774503 Accuracy: 79.88165680473372\n",
            "Epoch: 351 Training loss: 98.14508975241029 Accuracy: 74.55621301775149\n",
            "Epoch: 352 Training loss: 97.30621235500439 Accuracy: 79.88165680473372\n",
            "Epoch: 353 Training loss: 98.47620166188608 Accuracy: 78.69822485207101\n",
            "Epoch: 354 Training loss: 98.88484740320928 Accuracy: 76.33136094674556\n",
            "Epoch: 355 Training loss: 97.98750690441375 Accuracy: 80.4733727810651\n",
            "Epoch: 356 Training loss: 97.13421322830982 Accuracy: 75.7396449704142\n",
            "Epoch: 357 Training loss: 97.35277966054127 Accuracy: 78.10650887573965\n",
            "Epoch: 358 Training loss: 97.74560619006661 Accuracy: 79.88165680473372\n",
            "Epoch: 359 Training loss: 97.92879208530758 Accuracy: 80.4733727810651\n",
            "Epoch: 360 Training loss: 97.25199251290542 Accuracy: 72.18934911242604\n",
            "Epoch: 361 Training loss: 98.30680049394141 Accuracy: 79.28994082840237\n",
            "Epoch: 362 Training loss: 97.67304917114961 Accuracy: 75.14792899408283\n",
            "Epoch: 363 Training loss: 98.30620279363939 Accuracy: 78.69822485207101\n",
            "Epoch: 364 Training loss: 98.075553406994 Accuracy: 78.69822485207101\n",
            "Epoch: 365 Training loss: 97.74584799659351 Accuracy: 80.4733727810651\n",
            "Epoch: 366 Training loss: 97.2621301731051 Accuracy: 74.55621301775149\n",
            "Epoch: 367 Training loss: 97.70498880822925 Accuracy: 79.28994082840237\n",
            "Epoch: 368 Training loss: 96.65032663512102 Accuracy: 78.69822485207101\n",
            "Epoch: 369 Training loss: 98.19806766287002 Accuracy: 73.37278106508876\n",
            "Epoch: 370 Training loss: 97.41149175015016 Accuracy: 76.92307692307693\n",
            "Epoch: 371 Training loss: 97.95685762635549 Accuracy: 73.96449704142012\n",
            "Epoch: 372 Training loss: 97.35430540422385 Accuracy: 73.96449704142012\n",
            "Epoch: 373 Training loss: 97.5779552696913 Accuracy: 79.28994082840237\n",
            "Epoch: 374 Training loss: 98.28465019393843 Accuracy: 79.28994082840237\n",
            "Epoch: 375 Training loss: 97.74039282229114 Accuracy: 78.69822485207101\n",
            "Epoch: 376 Training loss: 96.83821998856001 Accuracy: 81.65680473372781\n",
            "Epoch: 377 Training loss: 97.64283704038098 Accuracy: 81.06508875739645\n",
            "Epoch: 378 Training loss: 97.24858192545616 Accuracy: 79.88165680473372\n",
            "Epoch: 379 Training loss: 97.21237166174797 Accuracy: 79.88165680473372\n",
            "Epoch: 380 Training loss: 98.24822637764328 Accuracy: 78.69822485207101\n",
            "Epoch: 381 Training loss: 96.96201799962728 Accuracy: 81.06508875739645\n",
            "Epoch: 382 Training loss: 96.29193605817272 Accuracy: 72.18934911242604\n",
            "Epoch: 383 Training loss: 97.4447660879232 Accuracy: 79.88165680473372\n",
            "Epoch: 384 Training loss: 97.39321642547293 Accuracy: 72.7810650887574\n",
            "Epoch: 385 Training loss: 97.1529462752078 Accuracy: 73.96449704142012\n",
            "Epoch: 386 Training loss: 96.26495986047667 Accuracy: 81.06508875739645\n",
            "Epoch: 387 Training loss: 96.86262948979856 Accuracy: 79.28994082840237\n",
            "Epoch: 388 Training loss: 96.47589303855966 Accuracy: 80.4733727810651\n",
            "Epoch: 389 Training loss: 96.99175614649175 Accuracy: 78.69822485207101\n",
            "Epoch: 390 Training loss: 97.4838430615855 Accuracy: 75.7396449704142\n",
            "Epoch: 391 Training loss: 96.56891866799924 Accuracy: 78.10650887573965\n",
            "Epoch: 392 Training loss: 97.14384663449528 Accuracy: 72.18934911242604\n",
            "Epoch: 393 Training loss: 96.99619432811778 Accuracy: 78.69822485207101\n",
            "Epoch: 394 Training loss: 96.61393138091807 Accuracy: 73.37278106508876\n",
            "Epoch: 395 Training loss: 97.13926551487384 Accuracy: 78.69822485207101\n",
            "Epoch: 396 Training loss: 96.72725159168476 Accuracy: 74.55621301775149\n",
            "Epoch: 397 Training loss: 96.97508329472839 Accuracy: 80.4733727810651\n",
            "Epoch: 398 Training loss: 97.12691264232444 Accuracy: 81.06508875739645\n",
            "Epoch: 399 Training loss: 97.03299139285446 Accuracy: 78.10650887573965\n",
            "Epoch: 400 Training loss: 96.97493643725466 Accuracy: 76.92307692307693\n",
            "Epoch: 401 Training loss: 96.67549903941836 Accuracy: 72.7810650887574\n",
            "Epoch: 402 Training loss: 97.17757377751695 Accuracy: 79.28994082840237\n",
            "Epoch: 403 Training loss: 97.16394230943934 Accuracy: 75.7396449704142\n",
            "Epoch: 404 Training loss: 97.35004229590413 Accuracy: 79.88165680473372\n",
            "Epoch: 405 Training loss: 96.50919707880894 Accuracy: 79.88165680473372\n",
            "Epoch: 406 Training loss: 96.16635761846544 Accuracy: 79.28994082840237\n",
            "Epoch: 407 Training loss: 97.26037151231185 Accuracy: 78.69822485207101\n",
            "Epoch: 408 Training loss: 97.19883181509431 Accuracy: 77.51479289940828\n",
            "Epoch: 409 Training loss: 96.75938101638894 Accuracy: 77.51479289940828\n",
            "Epoch: 410 Training loss: 97.2280172681385 Accuracy: 73.96449704142012\n",
            "Epoch: 411 Training loss: 96.37965240566245 Accuracy: 79.88165680473372\n",
            "Epoch: 412 Training loss: 97.17144161377655 Accuracy: 77.51479289940828\n",
            "Epoch: 413 Training loss: 97.22130301573725 Accuracy: 76.92307692307693\n",
            "Epoch: 414 Training loss: 96.5913789156564 Accuracy: 72.18934911242604\n",
            "Epoch: 415 Training loss: 96.31086418203267 Accuracy: 79.88165680473372\n",
            "Epoch: 416 Training loss: 94.13387493005393 Accuracy: 78.10650887573965\n",
            "Epoch: 417 Training loss: 95.08504527387959 Accuracy: 76.33136094674556\n",
            "Epoch: 418 Training loss: 96.85472755602314 Accuracy: 76.33136094674556\n",
            "Epoch: 419 Training loss: 96.29062882029666 Accuracy: 75.14792899408283\n",
            "Epoch: 420 Training loss: 96.37435524306011 Accuracy: 79.28994082840237\n",
            "Epoch: 421 Training loss: 96.50494149347469 Accuracy: 79.88165680473372\n",
            "Epoch: 422 Training loss: 95.8424513443806 Accuracy: 79.88165680473372\n",
            "Epoch: 423 Training loss: 97.05150154370494 Accuracy: 79.28994082840237\n",
            "Epoch: 424 Training loss: 95.4275981439132 Accuracy: 77.51479289940828\n",
            "Epoch: 425 Training loss: 95.84333805483584 Accuracy: 79.88165680473372\n",
            "Epoch: 426 Training loss: 95.20638359925033 Accuracy: 75.7396449704142\n",
            "Epoch: 427 Training loss: 95.50487632387558 Accuracy: 78.69822485207101\n",
            "Epoch: 428 Training loss: 96.31968206104133 Accuracy: 79.28994082840237\n",
            "Epoch: 429 Training loss: 96.20950979219924 Accuracy: 78.69822485207101\n",
            "Epoch: 430 Training loss: 94.67520770020928 Accuracy: 80.4733727810651\n",
            "Epoch: 431 Training loss: 96.28445725749953 Accuracy: 76.33136094674556\n",
            "Epoch: 432 Training loss: 95.70114942650798 Accuracy: 78.69822485207101\n",
            "Epoch: 433 Training loss: 95.66591895199963 Accuracy: 79.88165680473372\n",
            "Epoch: 434 Training loss: 95.3864451434456 Accuracy: 78.10650887573965\n",
            "Epoch: 435 Training loss: 96.6927087784643 Accuracy: 78.69822485207101\n",
            "Epoch: 436 Training loss: 96.39364082863312 Accuracy: 76.92307692307693\n",
            "Epoch: 437 Training loss: 94.98244706391415 Accuracy: 72.18934911242604\n",
            "Epoch: 438 Training loss: 94.08868951495606 Accuracy: 74.55621301775149\n",
            "Epoch: 439 Training loss: 96.14987607350031 Accuracy: 75.14792899408283\n",
            "Epoch: 440 Training loss: 94.15849753670409 Accuracy: 75.7396449704142\n",
            "Epoch: 441 Training loss: 96.18445258363136 Accuracy: 76.92307692307693\n",
            "Epoch: 442 Training loss: 95.28821936086388 Accuracy: 79.88165680473372\n",
            "Epoch: 443 Training loss: 96.36434721497062 Accuracy: 79.28994082840237\n",
            "Epoch: 444 Training loss: 94.40521413561055 Accuracy: 76.33136094674556\n",
            "Epoch: 445 Training loss: 95.61048258159099 Accuracy: 75.14792899408283\n",
            "Epoch: 446 Training loss: 95.82774386530127 Accuracy: 78.10650887573965\n",
            "Epoch: 447 Training loss: 95.6313339652088 Accuracy: 78.69822485207101\n",
            "Epoch: 448 Training loss: 95.9046676246162 Accuracy: 78.69822485207101\n",
            "Epoch: 449 Training loss: 95.61789151157609 Accuracy: 79.88165680473372\n",
            "Epoch: 450 Training loss: 96.33708842099804 Accuracy: 78.10650887573965\n",
            "Epoch: 451 Training loss: 96.15977617491353 Accuracy: 76.92307692307693\n",
            "Epoch: 452 Training loss: 96.21197690254121 Accuracy: 74.55621301775149\n",
            "Epoch: 453 Training loss: 95.75067500719342 Accuracy: 78.10650887573965\n",
            "Epoch: 454 Training loss: 95.72614769718894 Accuracy: 75.14792899408283\n",
            "Epoch: 455 Training loss: 95.73125738288218 Accuracy: 79.28994082840237\n",
            "Epoch: 456 Training loss: 93.9747681443132 Accuracy: 78.69822485207101\n",
            "Epoch: 457 Training loss: 95.59866545014575 Accuracy: 75.7396449704142\n",
            "Epoch: 458 Training loss: 95.35051752019399 Accuracy: 78.69822485207101\n",
            "Epoch: 459 Training loss: 95.3147193200125 Accuracy: 79.28994082840237\n",
            "Epoch: 460 Training loss: 95.0520370791819 Accuracy: 78.69822485207101\n",
            "Epoch: 461 Training loss: 95.40308405348333 Accuracy: 74.55621301775149\n",
            "Epoch: 462 Training loss: 93.57912888514613 Accuracy: 72.7810650887574\n",
            "Epoch: 463 Training loss: 96.00265027074965 Accuracy: 75.7396449704142\n",
            "Epoch: 464 Training loss: 94.91082191485475 Accuracy: 79.28994082840237\n",
            "Epoch: 465 Training loss: 95.4778758222019 Accuracy: 75.14792899408283\n",
            "Epoch: 466 Training loss: 95.2679933706163 Accuracy: 78.10650887573965\n",
            "Epoch: 467 Training loss: 95.6555184302706 Accuracy: 78.10650887573965\n",
            "Epoch: 468 Training loss: 94.32178603780085 Accuracy: 78.10650887573965\n",
            "Epoch: 469 Training loss: 95.70596276262586 Accuracy: 79.28994082840237\n",
            "Epoch: 470 Training loss: 94.98347120812201 Accuracy: 76.33136094674556\n",
            "Epoch: 471 Training loss: 95.16435797679878 Accuracy: 78.10650887573965\n",
            "Epoch: 472 Training loss: 95.57535387610551 Accuracy: 79.28994082840237\n",
            "Epoch: 473 Training loss: 95.46046979660878 Accuracy: 78.69822485207101\n",
            "Epoch: 474 Training loss: 96.10803148886589 Accuracy: 76.92307692307693\n",
            "Epoch: 475 Training loss: 95.83566326464279 Accuracy: 75.7396449704142\n",
            "Epoch: 476 Training loss: 95.12302088403158 Accuracy: 75.7396449704142\n",
            "Epoch: 477 Training loss: 94.64396904186287 Accuracy: 76.33136094674556\n",
            "Epoch: 478 Training loss: 95.9083723769545 Accuracy: 77.51479289940828\n",
            "Epoch: 479 Training loss: 95.23331570954542 Accuracy: 75.7396449704142\n",
            "Epoch: 480 Training loss: 93.53671202880469 Accuracy: 72.18934911242604\n",
            "Epoch: 481 Training loss: 95.12321033552803 Accuracy: 77.51479289940828\n",
            "Epoch: 482 Training loss: 93.45585878457496 Accuracy: 75.14792899408283\n",
            "Epoch: 483 Training loss: 95.12675489531102 Accuracy: 77.51479289940828\n",
            "Epoch: 484 Training loss: 95.10822578727493 Accuracy: 79.28994082840237\n",
            "Epoch: 485 Training loss: 94.29730432544693 Accuracy: 73.37278106508876\n",
            "Epoch: 486 Training loss: 95.87297140789678 Accuracy: 78.10650887573965\n",
            "Epoch: 487 Training loss: 94.4683231806755 Accuracy: 75.14792899408283\n",
            "Epoch: 488 Training loss: 95.02464028729628 Accuracy: 78.69822485207101\n",
            "Epoch: 489 Training loss: 94.77043866779422 Accuracy: 71.59763313609467\n",
            "Epoch: 490 Training loss: 94.9564746748365 Accuracy: 77.51479289940828\n",
            "Epoch: 491 Training loss: 94.1301980893586 Accuracy: 76.92307692307693\n",
            "Epoch: 492 Training loss: 94.81392428684921 Accuracy: 72.7810650887574\n",
            "Epoch: 493 Training loss: 94.47637754631705 Accuracy: 75.14792899408283\n",
            "Epoch: 494 Training loss: 95.06840634729451 Accuracy: 78.10650887573965\n",
            "Epoch: 495 Training loss: 95.390298835674 Accuracy: 76.33136094674556\n",
            "Epoch: 496 Training loss: 94.56524593231825 Accuracy: 78.69822485207101\n",
            "Epoch: 497 Training loss: 94.99640637620541 Accuracy: 78.69822485207101\n",
            "Epoch: 498 Training loss: 94.47344191324737 Accuracy: 75.14792899408283\n",
            "Epoch: 499 Training loss: 94.56919154445268 Accuracy: 78.69822485207101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}