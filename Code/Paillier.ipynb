{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Paillier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mrzx0bkRF-K",
        "outputId": "349ecc6b-b612-4015-b520-9b34b952512d"
      },
      "source": [
        "!git clone https://github.com/data61/python-paillier"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'python-paillier'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 997 (delta 5), reused 0 (delta 0), pack-reused 984\u001b[K\n",
            "Receiving objects: 100% (997/997), 281.07 KiB | 7.03 MiB/s, done.\n",
            "Resolving deltas: 100% (637/637), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I4WjPloTffW",
        "outputId": "0ce1f1bf-df2c-4f0f-fdfd-bfd62329a6c9"
      },
      "source": [
        "!apt-get install libgmp-dev\n",
        "!apt-get install libmpfr-dev\n",
        "!apt-get install libmpc-dev"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libgmpxx4ldbl\n",
            "Suggested packages:\n",
            "  gmp-doc libgmp10-doc libmpfr-dev\n",
            "The following NEW packages will be installed:\n",
            "  libgmp-dev libgmpxx4ldbl\n",
            "0 upgraded, 2 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 325 kB of archives.\n",
            "After this operation, 1,667 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgmpxx4ldbl amd64 2:6.1.2+dfsg-2 [8,964 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgmp-dev amd64 2:6.1.2+dfsg-2 [316 kB]\n",
            "Fetched 325 kB in 1s (480 kB/s)\n",
            "Selecting previously unselected package libgmpxx4ldbl:amd64.\n",
            "(Reading database ... 146442 files and directories currently installed.)\n",
            "Preparing to unpack .../libgmpxx4ldbl_2%3a6.1.2+dfsg-2_amd64.deb ...\n",
            "Unpacking libgmpxx4ldbl:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Selecting previously unselected package libgmp-dev:amd64.\n",
            "Preparing to unpack .../libgmp-dev_2%3a6.1.2+dfsg-2_amd64.deb ...\n",
            "Unpacking libgmp-dev:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Setting up libgmpxx4ldbl:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Setting up libgmp-dev:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libmpfr-doc\n",
            "The following NEW packages will be installed:\n",
            "  libmpfr-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 249 kB of archives.\n",
            "After this operation, 1,232 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmpfr-dev amd64 4.0.1-1 [249 kB]\n",
            "Fetched 249 kB in 1s (428 kB/s)\n",
            "Selecting previously unselected package libmpfr-dev:amd64.\n",
            "(Reading database ... 146460 files and directories currently installed.)\n",
            "Preparing to unpack .../libmpfr-dev_4.0.1-1_amd64.deb ...\n",
            "Unpacking libmpfr-dev:amd64 (4.0.1-1) ...\n",
            "Setting up libmpfr-dev:amd64 (4.0.1-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libmpc-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 50.5 kB of archives.\n",
            "After this operation, 280 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmpc-dev amd64 1.1.0-1 [50.5 kB]\n",
            "Fetched 50.5 kB in 0s (144 kB/s)\n",
            "Selecting previously unselected package libmpc-dev:amd64.\n",
            "(Reading database ... 146473 files and directories currently installed.)\n",
            "Preparing to unpack .../libmpc-dev_1.1.0-1_amd64.deb ...\n",
            "Unpacking libmpc-dev:amd64 (1.1.0-1) ...\n",
            "Setting up libmpc-dev:amd64 (1.1.0-1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH6xcH13SfF0",
        "outputId": "df86e3c9-924e-4d3a-caba-862c5d82b976"
      },
      "source": [
        "!pip3 install -r /content/python-paillier/requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycrypto>=2.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/db/645aa9af249f059cc3a368b118de33889219e0362141e75d4eaf6f80f163/pycrypto-2.6.1.tar.gz (446kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 5.5MB/s \n",
            "\u001b[?25hCollecting gmpy2>=2.0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/f4/9a2e384b325b69bc5827b9a6510a8fb4a51698c915c06a3f25a86458892a/gmpy2-2.0.8.zip (280kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from -r /content/python-paillier/requirements.txt (line 3)) (1.19.5)\n",
            "Collecting nose>=1.3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=6.7 in /usr/local/lib/python3.6/dist-packages (from -r /content/python-paillier/requirements.txt (line 5)) (7.1.2)\n",
            "Building wheels for collected packages: pycrypto, gmpy2\n",
            "  Building wheel for pycrypto (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycrypto: filename=pycrypto-2.6.1-cp36-cp36m-linux_x86_64.whl size=531522 sha256=e3fbca546cd19c6dfae4a0528d623eebae0bc757e3b7d2944f1657ffa367edc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/02/5e/77a69d0c16bb63c6ed32f5386f33a2809c94bd5414a2f6c196\n",
            "  Building wheel for gmpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gmpy2: filename=gmpy2-2.0.8-cp36-cp36m-linux_x86_64.whl size=456719 sha256=b3cfdbc34fad48f8d0dd8adac9a6dd79ad0c7bc6f829cedab7cd270510de385c\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/5a/45/b4f58933bc61064f49669220932d1d5bcc0b2a1f762f25ac0e\n",
            "Successfully built pycrypto gmpy2\n",
            "Installing collected packages: pycrypto, gmpy2, nose\n",
            "Successfully installed gmpy2-2.0.8 nose-1.3.7 pycrypto-2.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YRUV2PzUJU8",
        "outputId": "3931465a-cb00-407c-ebeb-8609c4bef6d6"
      },
      "source": [
        "!python /content/python-paillier/setup.py build"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/setuptools/dist.py:461: UserWarning: Normalizing '1.4.1-dev0' to '1.4.1.dev0'\n",
            "  warnings.warn(tmpl.format(**locals()))\n",
            "running build\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgsuBKuWUbqm",
        "outputId": "a0e00ca3-4db2-4bd4-ab61-fd012d862b48"
      },
      "source": [
        "!python /content/python-paillier/setup.py install"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/setuptools/dist.py:461: UserWarning: Normalizing '1.4.1-dev0' to '1.4.1.dev0'\n",
            "  warnings.warn(tmpl.format(**locals()))\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating phe.egg-info\n",
            "writing phe.egg-info/PKG-INFO\n",
            "writing dependency_links to phe.egg-info/dependency_links.txt\n",
            "writing entry points to phe.egg-info/entry_points.txt\n",
            "writing requirements to phe.egg-info/requires.txt\n",
            "writing top-level names to phe.egg-info/top_level.txt\n",
            "writing manifest file 'phe.egg-info/SOURCES.txt'\n",
            "reading manifest file 'phe.egg-info/SOURCES.txt'\n",
            "writing manifest file 'phe.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
            "\n",
            "creating build\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying phe.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying phe.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying phe.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying phe.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying phe.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying phe.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/phe-1.4.1.dev0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing phe-1.4.1.dev0-py3.6.egg\n",
            "Copying phe-1.4.1.dev0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding phe 1.4.1.dev0 to easy-install.pth file\n",
            "Installing pheutil script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/phe-1.4.1.dev0-py3.6.egg\n",
            "Processing dependencies for phe==1.4.1.dev0\n",
            "Finished processing dependencies for phe==1.4.1.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCLg3N8lSspP"
      },
      "source": [
        "#!python /content/python-paillier/setup.py test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsDliibKU8US",
        "outputId": "5328ab37-8e75-4b4a-8d98-5f37327f2c25"
      },
      "source": [
        "%cd /content/python-paillier/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/python-paillier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCKOpsA3Uc0k",
        "outputId": "20cc3653-fea0-4039-8cc4-3016b0516c7d"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "import phe as paillier\n",
        "\n",
        "seed = 43\n",
        "np.random.seed(seed)\n",
        "\n",
        "def get_data(n_clients):\n",
        "    \"\"\"\n",
        "    Import the dataset via sklearn, shuffle and split train/test.\n",
        "    Return training, target lists for `n_clients` and a holdout test set\n",
        "    \"\"\"\n",
        "    print(\"Loading data\")\n",
        "    diabetes = load_diabetes()\n",
        "    y = diabetes.target\n",
        "    X = diabetes.data\n",
        "    # Add constant to emulate intercept\n",
        "    X = np.c_[X, np.ones(X.shape[0])]\n",
        "\n",
        "    # The features are already preprocessed\n",
        "    # Shuffle\n",
        "    perm = np.random.permutation(X.shape[0])\n",
        "    X, y = X[perm, :], y[perm]\n",
        "\n",
        "    # Select test at random\n",
        "    test_size = 50\n",
        "    test_idx = np.random.choice(X.shape[0], size=test_size, replace=False)\n",
        "    train_idx = np.ones(X.shape[0], dtype=bool)\n",
        "    train_idx[test_idx] = False\n",
        "    X_test, y_test = X[test_idx, :], y[test_idx]\n",
        "    X_train, y_train = X[train_idx, :], y[train_idx]\n",
        "\n",
        "    # Split train among multiple clients.\n",
        "    # The selection is not at random. We simulate the fact that each client\n",
        "    # sees a potentially very different sample of patients.\n",
        "    X, y = [], []\n",
        "    step = int(X_train.shape[0] / n_clients)\n",
        "    for c in range(n_clients):\n",
        "        X.append(X_train[step * c: step * (c + 1), :])\n",
        "        y.append(y_train[step * c: step * (c + 1)])\n",
        "\n",
        "    return X, y, X_test, y_test\n",
        "\n",
        "\n",
        "def mean_square_error(y_pred, y):\n",
        "    \"\"\" 1/m * \\sum_{i=1..m} (y_pred_i - y_i)^2 \"\"\"\n",
        "    return np.mean((y - y_pred) ** 2)\n",
        "\n",
        "\n",
        "def encrypt_vector(public_key, x):\n",
        "    return [public_key.encrypt(i) for i in x]\n",
        "\n",
        "\n",
        "def decrypt_vector(private_key, x):\n",
        "    return np.array([private_key.decrypt(i) for i in x])\n",
        "\n",
        "\n",
        "def sum_encrypted_vectors(x, y):\n",
        "    if len(x) != len(y):\n",
        "        raise ValueError('Encrypted vectors must have the same size')\n",
        "    return [x[i] + y[i] for i in range(len(x))]\n",
        "\n",
        "\n",
        "class Server:\n",
        "    \"\"\"Private key holder. Decrypts the average gradient\"\"\"\n",
        "\n",
        "    def __init__(self, key_length):\n",
        "         keypair = paillier.generate_paillier_keypair(n_length=key_length)\n",
        "         self.pubkey, self.privkey = keypair\n",
        "\n",
        "    def decrypt_aggregate(self, input_model, n_clients):\n",
        "        return decrypt_vector(self.privkey, input_model) / n_clients\n",
        "\n",
        "\n",
        "class Client:\n",
        "    \"\"\"Runs linear regression with local data or by gradient steps,\n",
        "    where gradient can be passed in.\n",
        "    Using public key can encrypt locally computed gradients.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name, X, y, pubkey):\n",
        "        self.name = name\n",
        "        self.pubkey = pubkey\n",
        "        self.X, self.y = X, y\n",
        "        self.weights = np.zeros(X.shape[1])\n",
        "        self.predictionTreshold = 50\n",
        "\n",
        "    def fit(self, n_iter, eta=0.01):\n",
        "        \"\"\"Linear regression for n_iter\"\"\"\n",
        "        for _ in range(n_iter):\n",
        "            gradient = self.compute_gradient()\n",
        "            self.gradient_step(gradient, eta)\n",
        "\n",
        "    def gradient_step(self, gradient, eta=0.01):\n",
        "        \"\"\"Update the model with the given gradient\"\"\"\n",
        "        self.weights -= eta * gradient\n",
        "\n",
        "    def compute_gradient(self):\n",
        "        \"\"\"Compute the gradient of the current model using the training set\n",
        "        \"\"\"\n",
        "        delta = self.predict(self.X) - self.y\n",
        "        return delta.dot(self.X) / len(self.X)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Score test data\"\"\"\n",
        "        return X.dot(self.weights)\n",
        "\n",
        "    def encrypted_gradient(self, sum_to=None):\n",
        "        \"\"\"Compute and encrypt gradient.\n",
        "        When `sum_to` is given, sum the encrypted gradient to it, assumed\n",
        "        to be another vector of the same size\n",
        "        \"\"\"\n",
        "        gradient = self.compute_gradient()\n",
        "        encrypted_gradient = encrypt_vector(self.pubkey, gradient)\n",
        "\n",
        "        if sum_to is not None:\n",
        "            return sum_encrypted_vectors(sum_to, encrypted_gradient)\n",
        "        else:\n",
        "            return encrypted_gradient\n",
        "\n",
        "    def analyze_data_privacy(self, X, Y):\n",
        "      predicted = 0\n",
        "      notPredicted = 0\n",
        "      \n",
        "      # Data that has been predicted correctly\n",
        "      predictedDataX = []\n",
        "      predictedDataY = []\n",
        "\n",
        "      # Checking model's accuracy\n",
        "      for i in range(len(X)):\n",
        "        prediction = self.predict(X[i])\n",
        "\n",
        "        if(prediction >= Y[i] - self.predictionTreshold and prediction <= Y[i] + self.predictionTreshold):\n",
        "          predicted += 1\n",
        "          \n",
        "          predictedDataX.append(X[i])\n",
        "          predictedDataY.append(Y[i])\n",
        "        else:\n",
        "          notPredicted += 1\n",
        "\n",
        "      print(\"Predicted: {} Not predicted: {}\".format(predicted/(predicted+notPredicted)*100, notPredicted/(predicted+notPredicted)*100))\n",
        "\n",
        "      # Skaiciuojamas vidutinis maksimalus modelio epsilonas\n",
        "      increaseValues = np.repeat(0, 10)\n",
        "      dataIdxArr = np.repeat(1, 10)\n",
        "\n",
        "      for dataIdx in range(len(predictedDataX)):\n",
        "        for collumnIdx in range(len(X[0])):\n",
        "          label = predictedDataY[dataIdx]\n",
        "          data = predictedDataX[dataIdx]\n",
        "\n",
        "          y_prediction = self.predict(data)\n",
        "\n",
        "          if y_prediction >= label - self.predictionTreshold and y_prediction <= label + self.predictionTreshold:\n",
        "            epsilon = 0.1\n",
        "            increase = 0\n",
        "\n",
        "            dataIdxArr[collumnIdx] += 1\n",
        "\n",
        "            while((y_prediction >= label - self.predictionTreshold and y_prediction <= label + self.predictionTreshold) and increase < 100):\n",
        "              tempData = data\n",
        "              increase += epsilon\n",
        "              tempData[collumnIdx] += increase\n",
        "\n",
        "              y_prediction = self.predict(tempData)\n",
        "\n",
        "            increaseValues[collumnIdx] += increase\n",
        "        \n",
        "      # Showing output\n",
        "      for i in range(len(dataIdxArr)):\n",
        "        print(\"{}th collumn maximum epsilon: {}\".format(i, increaseValues[i]/dataIdxArr[i]))\n",
        "\n",
        "      s = 0\n",
        "      for i in range(10):\n",
        "        s += increaseValues[i]/dataIdxArr[i]\n",
        "\n",
        "      print(\"Model maximum epsilon: {}\".format(s/10))\n",
        "      print(\"Model treshold: {}\".format(self.predictionTreshold))\n",
        "\n",
        "def federated_learning(X, y, X_test, y_test, config):\n",
        "    n_clients = config['n_clients']\n",
        "    n_iter = config['n_iter']\n",
        "    names = ['Hospital {}'.format(i) for i in range(1, n_clients + 1)]\n",
        "\n",
        "    # Instantiate the server and generate private and public keys\n",
        "    # NOTE: using smaller keys sizes wouldn't be cryptographically safe\n",
        "    server = Server(key_length=config['key_length'])\n",
        "\n",
        "    # Instantiate the clients.\n",
        "    # Each client gets the public key at creation and its own local dataset\n",
        "    clients = []\n",
        "    for i in range(n_clients):\n",
        "        clients.append(Client(names[i], X[i], y[i], server.pubkey))\n",
        "\n",
        "    # The federated learning with gradient descent\n",
        "    print('Running distributed gradient aggregation for {:d} iterations'\n",
        "          .format(n_iter))\n",
        "    for i in range(n_iter):\n",
        "\n",
        "        # Compute gradients, encrypt and aggregate\n",
        "        encrypt_aggr = clients[0].encrypted_gradient(sum_to=None)\n",
        "        for c in clients[1:]:\n",
        "            encrypt_aggr = c.encrypted_gradient(sum_to=encrypt_aggr)\n",
        "\n",
        "        # Send aggregate to server and decrypt it\n",
        "        aggr = server.decrypt_aggregate(encrypt_aggr, n_clients)\n",
        "\n",
        "        # Take gradient steps\n",
        "        for c in clients:\n",
        "            c.gradient_step(aggr, config['eta'])\n",
        "\n",
        "    print('Error (MSE) that each client gets after running the protocol:')\n",
        "    for c in range(len(clients)):\n",
        "        y_pred = clients[c].predict(X_test)\n",
        "        mse = mean_square_error(y_pred, y_test)\n",
        "        print('{:s}:\\t{:.2f}'.format(clients[c].name, mse))\n",
        "\n",
        "        # Analyze client's data privacy\n",
        "        clients[c].analyze_data_privacy(X[c], y[c])\n",
        "\n",
        "def local_learning(X, y, X_test, y_test, config):\n",
        "    n_clients = config['n_clients']\n",
        "    names = ['Hospital {}'.format(i) for i in range(1, n_clients + 1)]\n",
        "\n",
        "    # Instantiate the clients.\n",
        "    # Each client gets the public key at creation and its own local dataset\n",
        "    clients = []\n",
        "    for i in range(n_clients):\n",
        "        clients.append(Client(names[i], X[i], y[i], None))\n",
        "\n",
        "    # Each client trains a linear regressor on its own data\n",
        "    print('Error (MSE) that each client gets on test set by '\n",
        "          'training only on own local data:')\n",
        "    for c in range(len(clients)):\n",
        "        clients[c].fit(config['n_iter'], config['eta'])\n",
        "        y_pred = clients[c].predict(X_test)\n",
        "        mse = mean_square_error(y_pred, y_test)\n",
        "\n",
        "        print('{:s}:\\t{:.2f}'.format(clients[c].name, mse))\n",
        "\n",
        "        # Analyze client's data privacy\n",
        "        clients[c].analyze_data_privacy(X[c], y[c])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    config = {\n",
        "        'n_clients': 1,\n",
        "        'key_length': 1024,\n",
        "        'n_iter': 2000,\n",
        "        'eta': 1.0,\n",
        "    }\n",
        "\n",
        "    X, y, X_test, y_test = get_data(n_clients=config['n_clients'])\n",
        "\n",
        "    #local_learning(X, y, X_test, y_test, config)\n",
        "\n",
        "    federated_learning(X, y, X_test, y_test, config)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data\n",
            "Running distributed gradient aggregation for 2000 iterations\n",
            "Error (MSE) that each client gets after running the protocol:\n",
            "Hospital 1:\t2202.75\n",
            "Predicted: 63.775510204081634 Not predicted: 36.224489795918366\n",
            "0th collumn maximum epsilon: 2.99203187250996\n",
            "1th collumn maximum epsilon: 0.0\n",
            "2th collumn maximum epsilon: 0.0\n",
            "3th collumn maximum epsilon: 0.0\n",
            "4th collumn maximum epsilon: 0.0\n",
            "5th collumn maximum epsilon: 0.0\n",
            "6th collumn maximum epsilon: 0.0\n",
            "7th collumn maximum epsilon: 0.0\n",
            "8th collumn maximum epsilon: 0.0\n",
            "9th collumn maximum epsilon: 0.0\n",
            "Model maximum epsilon: 0.29920318725099604\n",
            "Model treshold: 50\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}